{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theano Logistic Regression Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import theano\n",
    "import theano.tensor as T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 400\n",
    "feats = 784\n",
    "D = (numpy.random.randn(N, feats), numpy.random.randint(size=N, low=0, high=2))\n",
    "training_steps = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare Theano symbolic variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = T.matrix(\"x\")\n",
    "y = T.vector(\"y\")\n",
    "w = theano.shared(numpy.random.randn(feats), name=\"w\")\n",
    "b = theano.shared(0., name=\"b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Theano expression graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_1 = 1 / (1 + T.exp(-T.dot(x, w) - b)) # Probability that target = 1\n",
    "prediction = p_1 > 0.5 # The prediction thresholded\n",
    "xent = -y * T.log(p_1) - (1-y) * T.log(1-p_1) # Cross-entropy loss function\n",
    "cost = xent.mean() + 0.01 * (w ** 2).sum() # The cost to minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the gradient of the cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We shall return to this in a following section of this tutorial\n",
    "gw, gb = T.grad(cost, [w, b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = theano.function(\n",
    "          inputs=[x,y],\n",
    "          outputs=[prediction, xent],\n",
    "          updates=((w, w - 0.1 * gw), (b, b - 0.1 * gb)))\n",
    "predict = theano.function(inputs=[x], outputs=prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model:\n",
      "[-0.01518821 -0.01415944  0.00434382 -0.15363162 -0.18003992 -0.01253708\n",
      "  0.03651842  0.03146085 -0.1093249   0.07179806  0.0323893  -0.05965273\n",
      "  0.0911283   0.04459685  0.18428166 -0.08798417 -0.104639    0.00862909\n",
      "  0.00036649 -0.22661076 -0.26454289  0.03635827  0.14378412  0.1579776\n",
      "  0.07099326 -0.05328881 -0.01214565  0.06027384  0.09251733 -0.13439394\n",
      " -0.01135125 -0.10781403  0.0085375  -0.03371679  0.00039016  0.0022424\n",
      " -0.03139585  0.07057585  0.13070885 -0.11131814  0.0291172   0.01575916\n",
      " -0.04829049  0.1003439   0.09820573 -0.01081475  0.0602273   0.13837639\n",
      "  0.13733547  0.02449358  0.04701734 -0.11468713 -0.0281512   0.04503989\n",
      " -0.05598592  0.01593866  0.06985218  0.14745925 -0.06645025  0.08512957\n",
      " -0.04630519  0.03712248 -0.09766912 -0.16983958  0.00213887 -0.15186493\n",
      " -0.06347896  0.01726196 -0.34702372 -0.03402589  0.19021033 -0.07343035\n",
      "  0.02953966  0.07030712 -0.028319   -0.05501454  0.06830752 -0.03099222\n",
      " -0.08475477 -0.02768515 -0.10258879  0.139654   -0.00732272  0.01383491\n",
      " -0.0190226  -0.02976093  0.03720051 -0.01123117 -0.18349324 -0.04164528\n",
      "  0.03941828  0.1803161   0.05170415  0.01621775 -0.01637865  0.16130871\n",
      " -0.10738513  0.16350189  0.04310687 -0.078423    0.10730228  0.17071772\n",
      "  0.00114655  0.17005166 -0.15081978  0.06525108 -0.07677758 -0.06955066\n",
      "  0.10321372  0.01151559 -0.10449851 -0.10068642 -0.08081656 -0.1376268\n",
      "  0.00453331  0.09332095 -0.04851406  0.14157288 -0.04209108 -0.00715632\n",
      " -0.06038307  0.12346484 -0.08444268  0.11473783  0.11029869  0.02837034\n",
      "  0.0443933  -0.04959266 -0.00343798  0.04682393  0.03302898  0.07047871\n",
      "  0.04950254  0.17716922 -0.05150844 -0.08644799  0.04728201 -0.09099976\n",
      "  0.03879336 -0.09103162 -0.09916229 -0.03844498  0.00601476  0.08186217\n",
      " -0.1184194   0.03384822  0.08262664  0.07817899 -0.04482803 -0.21132767\n",
      "  0.06363462  0.05168124  0.1544881   0.0457307   0.00040148 -0.09130245\n",
      "  0.03295633  0.1322137   0.12951633  0.14710908 -0.1976854   0.14678239\n",
      "  0.05554121  0.01453006 -0.05018745 -0.0227487   0.09216696 -0.07575511\n",
      "  0.11501018  0.0112979   0.06445148  0.05237826  0.00248515 -0.05929413\n",
      "  0.12578466  0.07477399 -0.22779573 -0.03414946 -0.06945481 -0.09305921\n",
      " -0.02036558 -0.01482282  0.21473532 -0.04577378 -0.0311392   0.04781203\n",
      " -0.21669782  0.03777209 -0.09044542  0.0673077  -0.10605825  0.05927333\n",
      "  0.05621466 -0.11156061  0.16700794 -0.00729921  0.00206799 -0.0901445\n",
      " -0.07280279  0.05306754  0.12170339 -0.02702765 -0.12164241 -0.06368928\n",
      " -0.06774975 -0.02817663  0.08932532  0.20071858  0.09047085  0.13539427\n",
      " -0.00301267  0.06323661  0.0708155   0.23147374  0.07035773 -0.08556476\n",
      " -0.05349545 -0.00540902 -0.03341177 -0.03916649 -0.17899291 -0.02079621\n",
      " -0.01006593  0.0871134   0.02746141 -0.16039388  0.0347607   0.05044629\n",
      "  0.16080317 -0.10303997  0.21085437  0.05244533 -0.03333706 -0.10685403\n",
      "  0.12083711  0.08353928  0.06921778  0.04819781  0.04831696  0.15600749\n",
      "  0.07969113 -0.07889805  0.1340764  -0.03097043 -0.14431098  0.06271006\n",
      "  0.02810743 -0.10005507 -0.03087663 -0.01624026  0.12068306 -0.04109391\n",
      " -0.16218624  0.24055836 -0.0153128   0.03089266 -0.0719335  -0.03789285\n",
      "  0.02605399  0.09734989  0.04705669  0.02029947 -0.04895042 -0.00549105\n",
      " -0.17622741 -0.04848526 -0.09269998  0.01961373  0.0542522   0.1464714\n",
      " -0.16856223 -0.21315864 -0.20356258 -0.07721054  0.01010928  0.07905418\n",
      "  0.13339532 -0.11030807 -0.00109106 -0.11213055  0.12175318 -0.09232417\n",
      " -0.05180279  0.05905227  0.05511709 -0.01372202  0.05545929  0.03331409\n",
      "  0.1343195   0.06870589 -0.02128928  0.00138086  0.05636801 -0.08205171\n",
      " -0.01948108  0.02620311  0.01136177 -0.11708623 -0.01987043  0.0111175\n",
      " -0.1972769   0.02290634  0.03240229 -0.03721587 -0.01249811 -0.09211283\n",
      "  0.07299558 -0.0013909  -0.09727608  0.01781332  0.18953038  0.11689116\n",
      "  0.05994675 -0.01592236  0.00871545 -0.02931927 -0.00542967 -0.1208371\n",
      "  0.10438589  0.00067655  0.09274688  0.13152253 -0.01064892  0.1426182\n",
      "  0.00465904 -0.00319188  0.18791116  0.05212741 -0.02683163  0.0314131\n",
      "  0.05433035  0.16013006  0.06864464 -0.11774902 -0.00675029  0.04439888\n",
      "  0.15698529  0.0117717  -0.11569667  0.09026368  0.00192207  0.11406389\n",
      "  0.051482    0.01511091 -0.08950443  0.00061438 -0.04771448 -0.07887869\n",
      "  0.19038746  0.04040069  0.02641159  0.08379248  0.01338051  0.1087996\n",
      "  0.008209   -0.08857069 -0.01234049  0.02277718 -0.05611336 -0.02152441\n",
      "  0.11056399  0.12483608 -0.04285688 -0.03822721  0.10709144 -0.13122249\n",
      "  0.07147919 -0.0932529   0.04931255  0.18355751 -0.08569152  0.08817873\n",
      " -0.03469866 -0.08531113 -0.13630059 -0.0522616  -0.15077032  0.01438723\n",
      "  0.07048583  0.04130587 -0.0056054   0.13205561 -0.01818882  0.07425262\n",
      "  0.05403823  0.07478284  0.20877795  0.04724584 -0.03040824 -0.1737298\n",
      "  0.05981911 -0.08287446 -0.11298259  0.04566337 -0.1326485   0.15245329\n",
      " -0.02926078 -0.06785852 -0.00218279 -0.19287494 -0.04927408  0.11988121\n",
      "  0.04692162 -0.05626628 -0.07564174 -0.10312204 -0.17359742  0.15970503\n",
      "  0.04910149  0.14817334  0.11012467 -0.0093301   0.05087325 -0.03789495\n",
      " -0.13746717  0.09202789 -0.09305402 -0.13317446  0.05466723 -0.01673174\n",
      " -0.00189619  0.03910982 -0.13281409 -0.13573653  0.06613892  0.05081327\n",
      " -0.07061882 -0.09644281  0.00386269 -0.15820421 -0.10462876  0.10148745\n",
      " -0.00567658 -0.08908438  0.02006501 -0.23648591  0.00536579 -0.01448112\n",
      "  0.02166305 -0.03937986 -0.07096541  0.03848296 -0.04988948  0.04720423\n",
      " -0.04547478  0.06196231 -0.09130323  0.08502148  0.10346224  0.05945417\n",
      " -0.10329109  0.16074397  0.02271879 -0.00854734 -0.08946612  0.06299878\n",
      "  0.02845928  0.12859617 -0.03215913 -0.06512074  0.09683229 -0.11798835\n",
      " -0.06493889 -0.03257067  0.06948554  0.07093744 -0.09663394  0.02966159\n",
      "  0.0259706   0.16757858 -0.11712867 -0.06465317  0.03036364  0.10635959\n",
      " -0.08748743 -0.05614373  0.11036371  0.00418672 -0.01702634 -0.05952986\n",
      "  0.12345122  0.12003006  0.07865296 -0.16016737  0.00780112 -0.06019822\n",
      " -0.10943302 -0.0919618  -0.01682505 -0.0715706   0.00978025 -0.13777014\n",
      " -0.01279108 -0.08956119  0.20377844 -0.11369255  0.10839486 -0.05143589\n",
      " -0.16164113  0.01777591  0.0402765   0.04349426  0.11349059 -0.1026099\n",
      "  0.10371356 -0.09016624 -0.04067537  0.08111411  0.00733209  0.12001731\n",
      "  0.14988141 -0.03070392 -0.13424769 -0.04323143  0.04868205  0.02908824\n",
      " -0.05877445  0.08256924  0.10761346 -0.0461078  -0.00948927 -0.00535183\n",
      "  0.01228732 -0.07519659  0.09061153  0.13298727 -0.08134253  0.01833063\n",
      "  0.01411203  0.06687042 -0.15722401 -0.0066083   0.03015325  0.06832842\n",
      "  0.05007838  0.04652798 -0.11107217  0.09429493 -0.09278485  0.12134816\n",
      "  0.01595277  0.055017   -0.00633925 -0.0073372   0.02895206 -0.02511439\n",
      "  0.03266778  0.10936356 -0.01812076  0.14530994 -0.14464334  0.00494737\n",
      " -0.06490305  0.01776835 -0.0391816  -0.14103885  0.05630936 -0.03682512\n",
      "  0.10038304 -0.09252179 -0.16653103  0.1086468   0.12577597 -0.071615\n",
      "  0.06453359  0.06238701  0.01850113 -0.08627285 -0.06207385 -0.11705549\n",
      " -0.00810097 -0.07805973  0.00497541  0.01072829 -0.13408657 -0.08976989\n",
      " -0.04076632 -0.03803155 -0.07817076 -0.09198121  0.14463131 -0.07300127\n",
      " -0.0861982   0.0507548  -0.08404672  0.17547847  0.02712566 -0.04379191\n",
      "  0.14166026  0.12958166 -0.07395769 -0.28496316 -0.07372419  0.11725337\n",
      " -0.05953609  0.08014057 -0.03632851  0.07297395  0.05837134 -0.00394371\n",
      "  0.00929002 -0.02659053 -0.02006062 -0.00983456 -0.2509331   0.00359996\n",
      " -0.13434203  0.16836248  0.27965118 -0.02859427 -0.02733202 -0.03580176\n",
      "  0.0668259  -0.06421472 -0.07979707 -0.01346536  0.05757992  0.07867568\n",
      " -0.20336673 -0.01031832 -0.07731586 -0.0363354  -0.11869309  0.11124246\n",
      " -0.08721211 -0.04933146  0.00176186  0.09335803 -0.04923413  0.025501\n",
      " -0.07058645  0.08867328 -0.02569977 -0.10166435 -0.0985662   0.10260945\n",
      " -0.06241724 -0.10297295 -0.06052221  0.18570186 -0.05604991  0.22872069\n",
      "  0.01620374  0.13149059  0.15236689 -0.03532204  0.0370917  -0.10678983\n",
      " -0.01046837  0.09766467 -0.16649698  0.07736787 -0.02812329 -0.0223148\n",
      " -0.03494251 -0.15726516  0.15458041 -0.07523425 -0.136985    0.05023806\n",
      "  0.02872704 -0.1438302  -0.02067533 -0.06452159 -0.00174835  0.0452882\n",
      "  0.06203884  0.03138889 -0.0318898  -0.08602431 -0.00698207 -0.21044898\n",
      "  0.16965837  0.07644997  0.03344077 -0.10345747  0.13191004  0.16628112\n",
      "  0.01314628 -0.07135284 -0.02395773  0.05952339  0.02376553 -0.08022504\n",
      "  0.01126709  0.20972664 -0.00395065 -0.05025986 -0.21167239 -0.02566598\n",
      " -0.02996744  0.16212832  0.13182547  0.02412728 -0.09789827  0.0744245\n",
      "  0.00531508 -0.081074    0.04261393  0.08010709  0.07777614  0.02111036\n",
      "  0.17993258  0.08518202 -0.07645592 -0.09591016  0.04276494 -0.1518428\n",
      "  0.13287203 -0.05591256 -0.12798307 -0.04601365 -0.08495691 -0.08496643\n",
      "  0.00703039 -0.02616825 -0.09648786 -0.08803347 -0.09661472 -0.1079919\n",
      "  0.09583843 -0.14821326  0.02271918 -0.05730528  0.10413627 -0.03946288\n",
      "  0.0921182  -0.05336918 -0.13299327  0.1531822   0.14302354 -0.05911241\n",
      " -0.2063679  -0.05474127 -0.02806979  0.07865176 -0.06434923 -0.04675992\n",
      " -0.11335411  0.11336256 -0.14889961  0.13932094  0.03602042  0.11344148\n",
      "  0.01775588  0.04946916  0.1027732  -0.09961629  0.00477868  0.02232826\n",
      "  0.07252105  0.01427993 -0.07330039  0.04296168  0.12466024 -0.04903732\n",
      "  0.10672668 -0.04767137 -0.03317797  0.07301754 -0.05558261 -0.02755095\n",
      " -0.00058157  0.00230651 -0.00548832  0.10233269  0.00433892  0.05850353\n",
      " -0.16318414  0.05218348 -0.07669286 -0.01923595  0.02338924  0.14710643\n",
      " -0.03778507  0.06477412  0.07389316  0.05134815 -0.01436607 -0.09408838\n",
      "  0.02887067 -0.04089713 -0.00290052  0.08516766]\n",
      "-0.02983386827368895\n",
      "target values for D:\n",
      "[1 0 1 0 1 0 1 1 1 0 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 0\n",
      " 0 0 0 1 0 0 1 1 1 1 1 1 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0\n",
      " 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 1 1 1 0 0 1 1 0 1 0 0\n",
      " 1 1 1 1 1 0 1 0 1 1 0 1 0 0 1 0 1 1 0 1 1 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 1\n",
      " 0 0 1 0 0 0 1 0 1 0 0 1 1 1 0 0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 1 0 0 1 1 1 1 1 1 1 0 0 1 0 0 0 1 1 1 0 1 0 0 0 1 0 1 1 0 1 1 0 0 1 0 1 0\n",
      " 0 1 0 1 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0\n",
      " 0 1 1 0 0 1 0 0 0 0 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1\n",
      " 0 1 0 0 0 0 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 0 1 0\n",
      " 1 1 0 1 0 1 0 1 0 0 0 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 0 0 1 1 0\n",
      " 0 0 1 0 0 0 1 0 0 0 0 1 1 0 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0]\n",
      "prediction on D:\n",
      "[1 0 1 0 1 0 1 1 1 0 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 0\n",
      " 0 0 0 1 0 0 1 1 1 1 1 1 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0\n",
      " 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 1 1 1 0 0 1 1 0 1 0 0\n",
      " 1 1 1 1 1 0 1 0 1 1 0 1 0 0 1 0 1 1 0 1 1 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 1\n",
      " 0 0 1 0 0 0 1 0 1 0 0 1 1 1 0 0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 1 0 0 1 1 1 1 1 1 1 0 0 1 0 0 0 1 1 1 0 1 0 0 0 1 0 1 1 0 1 1 0 0 1 0 1 0\n",
      " 0 1 0 1 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0\n",
      " 0 1 1 0 0 1 0 0 0 0 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1\n",
      " 0 1 0 0 0 0 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 0 1 0\n",
      " 1 1 0 1 0 1 0 1 0 0 0 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 0 0 1 1 0\n",
      " 0 0 1 0 0 0 1 0 0 0 0 1 1 0 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "for i in range(training_steps):\n",
    "    pred, err = train(D[0], D[1])\n",
    "\n",
    "print(\"Final model:\")\n",
    "print(w.get_value())\n",
    "print(b.get_value())\n",
    "print(\"target values for D:\")\n",
    "print(D[1])\n",
    "print(\"prediction on D:\")\n",
    "print(predict(D[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Elemwise{exp,no_inplace}(<TensorType(float64, vector)>)]\n",
      "Looping 1000 times took 1.401809 seconds\n",
      "Result is [ 1.23178032  1.61879341  1.52278065 ...,  2.20771815  2.29967753\n",
      "  1.62323285]\n",
      "Used the cpu\n"
     ]
    }
   ],
   "source": [
    "from theano import function, config, shared, sandbox\n",
    "import theano.tensor as T\n",
    "import numpy\n",
    "import time\n",
    "\n",
    "vlen = 10 * 30 * 768  # 10 x #cores x # threads per core\n",
    "iters = 1000\n",
    "\n",
    "rng = numpy.random.RandomState(22)\n",
    "x = shared(numpy.asarray(rng.rand(vlen), config.floatX))\n",
    "f = function([], T.exp(x))\n",
    "print(f.maker.fgraph.toposort())\n",
    "t0 = time.time()\n",
    "for i in range(iters):\n",
    "    r = f()\n",
    "t1 = time.time()\n",
    "print(\"Looping %d times took %f seconds\" % (iters, t1 - t0))\n",
    "print(\"Result is %s\" % (r,))\n",
    "if numpy.any([isinstance(x.op, T.Elemwise) for x in f.maker.fgraph.toposort()]):\n",
    "    print('Used the cpu')\n",
    "else:\n",
    "    print('Used the gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
